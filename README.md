[![CI - Build Status](https://github.com/marcowolters91/programming-project-bandit/actions/workflows/ci.yml/badge.svg)](https://github.com/marcowolters91/programming-project-bandit/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/marcowolters91/programming-project-bandit/branch/main/graph/badge.svg)](https://codecov.io/gh/marcowolters91/programming-project-bandit)

# Multi-Armed Bandit â€“ Spotify Genre Optimizer

Ein Open-Source-Projekt zur Demonstration und Simulation von Multi-Armed-Bandit-Algorithmen im Kontext von **Musikempfehlungen auf Spotify**.  
Das Ziel ist es, verschiedene **Strategien zur Auswahl von Musikgenres** zu vergleichen, um **NutzerprÃ¤ferenzen datenbasiert zu optimieren**.

> Dieses Projekt wurde im Rahmen des Moduls *Programmierprojekt* an der Hochschule OsnabrÃ¼ck entwickelt.

---

## ProjektÃ¼bersicht

Der Multi-Armed Bandit simuliert ein Empfehlungssystem, das mit der Zeit lernt, welche Musikrichtungen ein Nutzer bevorzugt.  
Dabei wird das bekannte **Exploration-Exploitation-Dilemma** genutzt:  
Das System testet neue Genres (Exploration), wÃ¤hrend es gleichzeitig bekannte Favoriten hÃ¤ufiger empfiehlt (Exploitation).

Im konkreten Use Case werden **Spotify-Genres** wie *Pop*, *Hip-Hop*, *Jazz*, *Techno* oder *Indie* verwendet.  
Nach jeder â€žWiedergabeâ€œ bewertet der Nutzer die Empfehlung â€“ positiv oder negativ â€“ und der Algorithmus passt sich adaptiv an.  
So entsteht ein System, das Schritt fÃ¼r Schritt **lernt, welche Musik am besten ankommt**.

---

## ðŸŽµ Bandit-Varianten im Detail

### ðŸŽ¯ Bernoulli-Bandit

Du willst wissen, ob dein Musikgeschmack gerade der absolute Trend ist?  
Dann bist du hier genau richtig!

In dieser Variante werden die Genres als **Arme des Banditen** dargestellt â€“ jede Entscheidung ist ein Wurf ins musikalische GlÃ¼ck.

**Eintretende Rewards:**
- **1:** Treffer â€“ Das Genre gefÃ¤llt dem Nutzer!  
- **0:** Kein Treffer â€“ Das Genre wird geskippt.

Die Regeln sind einfach:  
WÃ¤hle, hÃ¶re und bewerte â€“ aber aufgepasst: **es geht auf Zeit!**  
Nur wer schnell und klug entscheidet, findet das aktuell **beliebteste Genre**.  

Doch sei gewarnt:  
Du bist **nicht allein im Spiel** â€“ deine Gegner sind unsichtbar, aber aktiv.  
Ihr alle wetteifert darum, den optimalen Musiktrend zuerst zu entdecken!

---

### ðŸ“ˆ Gaussian-Bandit

Analysiere verschiedene Musikgenre-Strategien auf Basis einer **normalverteilten Reward-Struktur**.  
Hier geht es nicht nur um Treffer oder Nieten, sondern um **graduelle Bewertungen** â€“ wie sehr ein Genre gefallen hat.  

Das Modell erlaubt feinere Nuancen und eignet sich ideal, um Unterschiede zwischen Ã¤hnlichen Genres zu erfassen.  
So wird erkennbar, **welche Strategie langfristig die beste Balance zwischen Risiko und Belohnung** liefert.

---

## Technologien

- **React (Vite)** â€“ Frontend-Framework zur Darstellung und Interaktion  
- **Node.js** â€“ Lokaler Entwicklungsserver & Paketverwaltung  
- **Vitest** â€“ Testing Framework fÃ¼r Unit- und Integrationstests  
- **ESLint + Prettier** â€“ CodequalitÃ¤t & Formatierung  
- **GitHub Actions** â€“ Continuous Integration (CI) mit automatisierten Tests  
- **Codecov** â€“ Testabdeckung und QualitÃ¤tsanalyse  

---

## Lokale Installation & Start

### Schritte

1. Repository klonen:
   ```bash
   git clone https://github.com/marcowolters91/programming-project-bandit.git
   ```

2. In den Projektordner wechseln:
   ```bash
   cd programming-project-bandit/multiarm-bandit
   ```

3. AbhÃ¤ngigkeiten installieren:
   ```bash
   npm install
   ```

4. Entwicklungsserver starten:
   ```bash
   npm run dev
   ```

5. Anwendung Ã¶ffnen:
   ```
   http://localhost:5173
   ```

---

## Funktionsweise

Das System implementiert mehrere **Bandit-Strategien** zur Optimierung der Musikempfehlungen:

- **Greedy-Algorithmus** â€“ WÃ¤hlt immer das aktuell beste Genre  
- **Epsilon-Greedy** â€“ Erkundet gelegentlich neue Genres  
- **Upper Confidence Bound (UCB)** â€“ Balanciert Risiko und Belohnung  
- **Thompson Sampling** â€“ Wahrscheinlichkeitsbasiertes Lernen  

Diese Strategien werden in Simulationen verglichen.  
Das Frontend visualisiert die Lernprozesse â€“ z. B.:
- HÃ¤ufigkeit der Genre-Auswahl  
- Durchschnittliche Belohnung  
- Lernkurven und Konvergenzverhalten  

So kann beobachtet werden, **wie jede Strategie mit der Zeit â€žintelligenterâ€œ wird**.

---

## Tests ausfÃ¼hren

Das Projekt nutzt **Vitest** fÃ¼r automatisierte Tests und Coverage-Berichte.

```bash
npm run coverage
```

Testberichte (Coverage) werden automatisch im Terminal ausgegeben.

---

## Continuous Integration

Das Repository enthÃ¤lt eine **GitHub Actions Workflow-Datei** (`.github/workflows/ci.yml`),  
die bei jedem Push automatisch:

1. Den Code lintet  
2. Den Code mit Prettier formatiert  
3. Die Tests mit Vitest ausfÃ¼hrt  
4. Einen Build erstellt  
5. Die Testabdeckung an Codecov Ã¼bermittelt  

---

## ErweiterungsmÃ¶glichkeiten (Ausblick)

- Integration echter **Spotify-APIs** zur Auswertung von HÃ¶rgewohnheiten  
- Verwendung von **realen Feedbackdaten** statt Simulation  
- Erweiterung um **personalisierte Nutzerprofile**  
- Interaktive **Lernvisualisierung** mit Zeitlimit oder Scoreboard  
- Vergleich mehrerer Spielerstrategien in Echtzeit  

---

## Team & Projektmanagement

- Hochschule OsnabrÃ¼ck â€“ Modul *Programmierprojekt (5. Semester)*  
- Projektorganisation Ã¼ber GitHub (Issues, Pull Requests, CI)  
- Kommunikation Ã¼ber MS Teams & Jira  

---

## Lizenz

Dieses Projekt ist **Open Source** und ausschlieÃŸlich zu **Lern- und Demonstrationszwecken** gedacht.

---

Â© 2025 Hochschule OsnabrÃ¼ck â€“ Multi-Armed Bandit Projekt
